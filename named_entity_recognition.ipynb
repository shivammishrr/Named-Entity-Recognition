{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <span style=\"font-family:cursive;text-align:center\">⬇️ Import Libraries</span>","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport glob\nimport os\nfrom datasets import Dataset\nimport torch\n# Set the display options for pandas\npd.set_option('display.max_colwidth', 200)\npd.set_option('display.max_rows', None)","metadata":{"_uuid":"97c71c8d-7937-4d79-89ba-b94bd489ae0f","_cell_guid":"559d757d-a50c-4e6a-ac59-8382786a17ed","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T07:04:09.105879Z","iopub.execute_input":"2023-09-17T07:04:09.106256Z","iopub.status.idle":"2023-09-17T07:04:14.662540Z","shell.execute_reply.started":"2023-09-17T07:04:09.106221Z","shell.execute_reply":"2023-09-17T07:04:14.661497Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the device to cuda if available, otherwise cpu\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","metadata":{"_uuid":"4f43d1f4-2322-461c-b9ca-8f104f7da7d2","_cell_guid":"384f8846-574a-418d-ac7c-eb11c04ce7c0","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T07:04:17.511281Z","iopub.execute_input":"2023-09-17T07:04:17.512387Z","iopub.status.idle":"2023-09-17T07:04:17.595892Z","shell.execute_reply.started":"2023-09-17T07:04:17.512350Z","shell.execute_reply":"2023-09-17T07:04:17.594687Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"font-family:cursive;text-align:center\">⬇️ Import Data</span>","metadata":{"_uuid":"9368d9b4-c7ac-40fd-a3ac-6f78329b239e","_cell_guid":"b03a8b54-dedd-4f0c-b88b-8d96962f8eb7","trusted":true}},{"cell_type":"code","source":"# Load the data from a tsv file\ndata = pd.read_csv(\"/kaggle/input/demo-data/dataset/train/boxes_transcripts_labels/004a4c67-561d-4d9c-9ef2-47cb15fbdf08_document-3_page-1.tsv\", header = None)\n# Assign column names to the data\ndata.columns = ['start_index', 'end_index', 'x_top_left', 'y_top_left', 'x_bottom_right', 'y_bottom_right', 'transcript', 'field']","metadata":{"_uuid":"06010967-ba23-49e8-a7cd-acb929d7fa86","_cell_guid":"e7cdb051-fc24-4061-b2f5-287669e3ca28","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T07:04:25.104948Z","iopub.execute_input":"2023-09-17T07:04:25.105326Z","iopub.status.idle":"2023-09-17T07:04:25.138764Z","shell.execute_reply.started":"2023-09-17T07:04:25.105294Z","shell.execute_reply":"2023-09-17T07:04:25.137807Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.sample(100)","metadata":{"_uuid":"b3187d1a-eafb-4917-8592-67a03c43b68c","_cell_guid":"98338047-c0bf-4699-94fe-ce0f95769d1b","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-17T07:04:26.509578Z","iopub.execute_input":"2023-09-17T07:04:26.509964Z","iopub.status.idle":"2023-09-17T07:04:26.559951Z","shell.execute_reply.started":"2023-09-17T07:04:26.509934Z","shell.execute_reply":"2023-09-17T07:04:26.558764Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['field'].unique()","metadata":{"_uuid":"7ba8e892-4cc4-49c4-b29f-bb046402b57c","_cell_guid":"142b2d02-7cab-408f-8f9d-cebbc3d5120e","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T07:04:27.809417Z","iopub.execute_input":"2023-09-17T07:04:27.809793Z","iopub.status.idle":"2023-09-17T07:04:27.822599Z","shell.execute_reply.started":"2023-09-17T07:04:27.809756Z","shell.execute_reply":"2023-09-17T07:04:27.821584Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a dictionary of ner labels and their corresponding numeric codes\nner_labels = { 0 : \"OTHER\",\n1 : \"employerName\",\n2 : \"employerAddressStreet_name\",\n3 : \"employerAddressCity\",\n4 : \"employerAddressState\",\n5 : \"employerAddressZip\",\n6 : \"einEmployerIdentificationNumber\",\n7 : \"employeeName\",\n8 : \"ssnOfEmployee\",\n9 : \"box1WagesTipsAndOtherCompensations\",\n10 : \"box2FederalIncomeTaxWithheld\",\n11 : \"box3SocialSecurityWages\",\n12 : \"box4SocialSecurityTaxWithheld\",\n13 : \"box16StateWagesTips\",\n14 : \"box17StateIncomeTax\",\n15 : \"taxYear\"\n}","metadata":{"_uuid":"073eb38e-3784-4669-9a0f-4d5d803bbb1b","_cell_guid":"f2062594-f4be-49a4-acb3-d484ed2fb6e5","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T07:04:28.909980Z","iopub.execute_input":"2023-09-17T07:04:28.910343Z","iopub.status.idle":"2023-09-17T07:04:28.916788Z","shell.execute_reply.started":"2023-09-17T07:04:28.910312Z","shell.execute_reply":"2023-09-17T07:04:28.915462Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a reverse dictionary of ner labels and their numeric codes\nner_labels_dict = {}\nfor key in ner_labels.keys():\n    ner_labels_dict.update({ner_labels[key] : key})","metadata":{"_uuid":"90981b12-9d5b-40e9-87bc-ab3e740fc320","_cell_guid":"f61c370f-19f7-44a3-a3d3-7e46393f1d40","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T07:04:30.081381Z","iopub.execute_input":"2023-09-17T07:04:30.082076Z","iopub.status.idle":"2023-09-17T07:04:30.089024Z","shell.execute_reply.started":"2023-09-17T07:04:30.082041Z","shell.execute_reply":"2023-09-17T07:04:30.086338Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ner_labels_dict","metadata":{"_uuid":"d1007d5f-307f-4232-ad3f-415644fb5517","_cell_guid":"44fbfabc-8d31-46e8-8a36-aa3ce573f5b8","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T07:04:34.153945Z","iopub.execute_input":"2023-09-17T07:04:34.154357Z","iopub.status.idle":"2023-09-17T07:04:34.161413Z","shell.execute_reply.started":"2023-09-17T07:04:34.154328Z","shell.execute_reply":"2023-09-17T07:04:34.160440Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a new column in the data with the numeric codes for the ner tags\ndata['ner_tags'] = data['field'].map(lambda x: ner_labels_dict[x])","metadata":{"_uuid":"c1cb05ae-ea18-4c2e-aff1-78198df7b03d","_cell_guid":"4fd525ef-9025-4224-820f-63d39601285a","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T07:04:36.284172Z","iopub.execute_input":"2023-09-17T07:04:36.285108Z","iopub.status.idle":"2023-09-17T07:04:36.292413Z","shell.execute_reply.started":"2023-09-17T07:04:36.285073Z","shell.execute_reply":"2023-09-17T07:04:36.291302Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the ner tags column to a list\ndata['ner_tags'].to_list()","metadata":{"_uuid":"eea9ecee-ad72-41f8-b9e1-67c24a357697","_cell_guid":"b457cd66-ba2c-448e-81ee-78f855cf6a91","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-17T07:04:37.922508Z","iopub.execute_input":"2023-09-17T07:04:37.923913Z","iopub.status.idle":"2023-09-17T07:04:37.942121Z","shell.execute_reply.started":"2023-09-17T07:04:37.923868Z","shell.execute_reply":"2023-09-17T07:04:37.941083Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the transcript column to a list\ndata['transcript'].to_list()","metadata":{"_uuid":"ead6ab09-8424-48db-8f47-707f6a6a7587","_cell_guid":"01f1d4c4-8d75-470f-aa95-43d23601d404","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-17T07:04:42.070748Z","iopub.execute_input":"2023-09-17T07:04:42.071199Z","iopub.status.idle":"2023-09-17T07:04:42.099850Z","shell.execute_reply.started":"2023-09-17T07:04:42.071160Z","shell.execute_reply":"2023-09-17T07:04:42.098926Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the unique values of the ner tags column\ndata['ner_tags'].unique()","metadata":{"_uuid":"51830fdb-6ebe-4004-baa6-4367788ebc3f","_cell_guid":"6083781d-a9d0-4446-bad3-7694e1e6e02d","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T07:04:43.226967Z","iopub.execute_input":"2023-09-17T07:04:43.227752Z","iopub.status.idle":"2023-09-17T07:04:43.237002Z","shell.execute_reply.started":"2023-09-17T07:04:43.227714Z","shell.execute_reply":"2023-09-17T07:04:43.235768Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a function to load data from a given path\ndef load_data(path):\n    directory = path\n    # Get all the tsv files in the directory\n    tsv_file = glob.glob(directory + '/*.tsv')\n    # Create an empty dataframe with two columns: transcript and ner_tags\n    data = pd.DataFrame(columns = ['transcript', 'ner_tags'])\n    # Loop through each tsv file in the directory\n    for filename in tsv_file:\n        # Read the tsv file as a dataframe\n        data_i = pd.read_csv(filename, header=None)\n        # Assign column names to the dataframe\n        data_i.columns = ['start_index', 'end_index', 'x_top_left', 'y_top_left', 'x_bottom_right', 'y_bottom_right', 'transcript', 'field']\n        # Drop any rows that have missing values in the transcript column\n        data_i.dropna(subset=['transcript'], inplace=True)\n        # Convert the transcript column to a list\n        transcript = data_i['transcript'].to_list()\n        # Map the field column to the numeric codes using the reverse dictionary\n        data_i['field'] = data_i['field'].map(lambda x: ner_labels_dict[x])\n        # Convert the field column to a list of ner tags\n        ner_labels = data_i['field'].to_list()\n        # Get the length of the transcript list\n        transcript_len = len(transcript)\n        \n        # If the transcript list is longer than 300, split it into two parts and append them as separate rows in the data dataframe\n        if transcript_len > 300:\n            transcript_1 = transcript[:(transcript_len//2)]\n            ner_labels_1 = ner_labels[:(transcript_len//2)]\n            transcript_2 = transcript[(transcript_len//2):]\n            ner_labels_2 = ner_labels[(transcript_len//2):]\n            data.loc[len(data)] = [transcript_1, ner_labels_1]\n            data.loc[len(data)] = [transcript_2, ner_labels_2]\n        # Otherwise, append the transcript list and the ner tags list as a single row in the data dataframe    \n        else:\n            data.loc[len(data)] = [transcript, ner_labels]\n    # Return the data dataframe\n    return data","metadata":{"_uuid":"8e7d72aa-e149-4d88-a389-1c62bd69919c","_cell_guid":"d33715aa-2550-4823-8c26-e8d487a921fc","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-17T07:04:44.212453Z","iopub.execute_input":"2023-09-17T07:04:44.213143Z","iopub.status.idle":"2023-09-17T07:04:44.223826Z","shell.execute_reply.started":"2023-09-17T07:04:44.213108Z","shell.execute_reply":"2023-09-17T07:04:44.222610Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Measure the execution time of loading the train and validation data\n%%time\ntrain_data = load_data('/kaggle/input/demo-data/dataset/train/boxes_transcripts_labels')\nval_data = load_data('/kaggle/input/demo-data/dataset/val_w_ann/boxes_transcripts_labels')","metadata":{"_uuid":"83dca32b-74e9-4ac9-9e0c-8660c9f16ed0","_cell_guid":"ee224514-16d5-4c00-9a97-c452ef53cd4c","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-17T07:04:45.476440Z","iopub.execute_input":"2023-09-17T07:04:45.476853Z","iopub.status.idle":"2023-09-17T07:04:54.935179Z","shell.execute_reply.started":"2023-09-17T07:04:45.476820Z","shell.execute_reply":"2023-09-17T07:04:54.934063Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.loc[0]","metadata":{"_uuid":"1552f3ba-5476-43de-b382-089243ee0e17","_cell_guid":"59c9ae37-80a1-400b-a68f-92f35d5382c7","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T07:04:56.416372Z","iopub.execute_input":"2023-09-17T07:04:56.417641Z","iopub.status.idle":"2023-09-17T07:04:56.427860Z","shell.execute_reply.started":"2023-09-17T07:04:56.417594Z","shell.execute_reply":"2023-09-17T07:04:56.426636Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_data.head()","metadata":{"_uuid":"dd3fc486-3554-4872-86ca-561c8d3c1763","_cell_guid":"f7f9dfd5-72d8-4d31-80ec-26043a113e68","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T07:04:59.032884Z","iopub.execute_input":"2023-09-17T07:04:59.033657Z","iopub.status.idle":"2023-09-17T07:04:59.057885Z","shell.execute_reply.started":"2023-09-17T07:04:59.033612Z","shell.execute_reply":"2023-09-17T07:04:59.056599Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.shape, val_data.shape","metadata":{"_uuid":"01cd9f20-9047-4f41-ba5b-33c354d583ec","_cell_guid":"b7915cec-1049-4dcf-99ce-c9ce34a0f5bb","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T07:05:00.624518Z","iopub.execute_input":"2023-09-17T07:05:00.624940Z","iopub.status.idle":"2023-09-17T07:05:00.633659Z","shell.execute_reply.started":"2023-09-17T07:05:00.624909Z","shell.execute_reply":"2023-09-17T07:05:00.631401Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transformer preprocessing","metadata":{"_uuid":"c755683d-6f11-4457-8170-2669100765db","_cell_guid":"c4ab970a-02c2-4e72-82c2-62497ad22937","trusted":true}},{"cell_type":"code","source":"# Show the first row of the train data\nfrom transformers import AutoTokenizer\n# Load the tokenizer for the distilbert-base-uncased model\ntokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")","metadata":{"_uuid":"ba402d61-e988-439b-befa-8679a027baec","_cell_guid":"3633c41c-ba9b-4427-b800-e8adc9e9dd37","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T07:05:10.045925Z","iopub.execute_input":"2023-09-17T07:05:10.046510Z","iopub.status.idle":"2023-09-17T07:05:13.895970Z","shell.execute_reply.started":"2023-09-17T07:05:10.046465Z","shell.execute_reply":"2023-09-17T07:05:13.894905Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the first transcript and ner tags from the train data\nexample_1 = train_data['transcript'][0]\nner = train_data['ner_tags'][0]","metadata":{"_uuid":"6d40aa2c-c4c1-4882-a930-44f3d7e666d1","_cell_guid":"bbe94677-1f4f-42e2-8bb7-ce8c44139571","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-17T07:05:13.901005Z","iopub.execute_input":"2023-09-17T07:05:13.903882Z","iopub.status.idle":"2023-09-17T07:05:13.911439Z","shell.execute_reply.started":"2023-09-17T07:05:13.903842Z","shell.execute_reply":"2023-09-17T07:05:13.910623Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenize the transcript using the tokenizer\ntokens = tokenizer(example_1, is_split_into_words=True, truncation=True)\n# Show the tokens\ntokens","metadata":{"_uuid":"9dc80632-a103-4336-92f5-43bb4995b0ff","_cell_guid":"8fd081b4-74c6-43f8-be0d-8421a7c340cb","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-17T07:05:20.703606Z","iopub.execute_input":"2023-09-17T07:05:20.704162Z","iopub.status.idle":"2023-09-17T07:05:20.721563Z","shell.execute_reply.started":"2023-09-17T07:05:20.704131Z","shell.execute_reply":"2023-09-17T07:05:20.720481Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a function to tokenize a given data\ndef tokenize_func(data):\n    # Return the tokenized transcript using the tokenizer\n    return tokenizer(data['transcript'], is_split_into_words=True, truncation=True)","metadata":{"_uuid":"0b58acf6-7c48-4577-8623-9032e40a6e4c","_cell_guid":"47d9e72d-64d7-4522-8dcc-1c44c2b7f5fb","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T07:05:25.242533Z","iopub.execute_input":"2023-09-17T07:05:25.242930Z","iopub.status.idle":"2023-09-17T07:05:25.249252Z","shell.execute_reply.started":"2023-09-17T07:05:25.242899Z","shell.execute_reply":"2023-09-17T07:05:25.247603Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a function to tokenize a given data\ndef tokenize_data(data):\n    # Convert the data to a Dataset object from the datasets library\n    data = Dataset.from_pandas(data)\n    # Apply the tokenize function to the data and map it to a new column\n    data = data.map(tokenize_func)\n    # Remove the index column from the data\n    data = data.remove_columns(['__index_level_0__'])\n    # Return the data as a pandas dataframe\n    return data.to_pandas()","metadata":{"_uuid":"7061632f-4986-469b-802f-6602ed9ef597","_cell_guid":"5e818883-495b-47c3-9fd6-f9308c742a2f","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T07:05:26.298631Z","iopub.execute_input":"2023-09-17T07:05:26.299129Z","iopub.status.idle":"2023-09-17T07:05:26.305444Z","shell.execute_reply.started":"2023-09-17T07:05:26.299095Z","shell.execute_reply":"2023-09-17T07:05:26.303879Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the transcript column from the train data\ntrain_data['transcript']","metadata":{"_uuid":"a31f911d-833e-470f-92d9-c4136ac8653f","_cell_guid":"6bfd6ddc-07cd-4124-b667-f9e3a63ea62a","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-17T07:05:27.041812Z","iopub.execute_input":"2023-09-17T07:05:27.042688Z","iopub.status.idle":"2023-09-17T07:05:27.504253Z","shell.execute_reply.started":"2023-09-17T07:05:27.042647Z","shell.execute_reply":"2023-09-17T07:05:27.503059Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenize the train and validation data and convert them to pandas dataframes\ntrain = tokenize_data(train_data)\nval = tokenize_data(val_data)","metadata":{"_uuid":"1367ab8c-2eab-470f-b958-c2d2ac2df2b5","_cell_guid":"a11844d0-1827-43b9-a556-6c20c49539f9","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T07:05:28.683675Z","iopub.execute_input":"2023-09-17T07:05:28.684076Z","iopub.status.idle":"2023-09-17T07:05:32.547573Z","shell.execute_reply.started":"2023-09-17T07:05:28.684045Z","shell.execute_reply":"2023-09-17T07:05:32.546481Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"_uuid":"dd1d9a60-2650-48df-8f4a-ad2a415979ed","_cell_guid":"1bdc72c0-22e2-461b-827b-9ac4ff7cd7fa","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-17T07:05:33.649861Z","iopub.execute_input":"2023-09-17T07:05:33.650961Z","iopub.status.idle":"2023-09-17T07:05:33.696867Z","shell.execute_reply.started":"2023-09-17T07:05:33.650922Z","shell.execute_reply":"2023-09-17T07:05:33.695739Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a function to create ner tags for each token in a given transcript and ner tags list\ndef create_ner_tags(tokens, ner_tags):\n    # Preprocess the tokens using the tokenizer\n    preprocessed_tokens = tokenizer(tokens, is_split_into_words=True, truncation=True)\n    # Get the input ids and word ids from the preprocessed tokens\n    input_ids = preprocessed_tokens['input_ids']\n    word_ids = preprocessed_tokens.word_ids()\n    \n    # Create an empty list for storing the ner tags for each token\n    ner_tags_for_tokens = []\n    # Loop through each token id in the input ids list\n    for ind, token in enumerate(input_ids):\n        # If the word id is None, append -100 to the ner tags list (this means that this token will be ignored for loss calculation)\n        if word_ids[ind] == None:\n            ner_tags_for_tokens.append(-100)\n        # If the word id is equal to the previous word id, append -100 to the ner tags list (this means that this token is part of a subword and will be ignored for loss calculation)\n        elif word_ids[ind] == word_ids[ind - 1]:\n            ner_tags_for_tokens.append(-100)\n        # Otherwise, append the corresponding ner tag from the ner tags list (this means that this token is a whole word and will be used for loss calculation)\n        else:\n            ner_tags_for_tokens.append(ner_tags[word_ids[ind]])\n    # Return the ner tags for tokens list\n    return ner_tags_for_tokens","metadata":{"_uuid":"03bcb305-2dbd-42d4-9629-e50084345b62","_cell_guid":"18804282-3016-4f87-bcc2-971b7a19ff4a","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T07:05:36.717494Z","iopub.execute_input":"2023-09-17T07:05:36.717896Z","iopub.status.idle":"2023-09-17T07:05:36.725961Z","shell.execute_reply.started":"2023-09-17T07:05:36.717866Z","shell.execute_reply":"2023-09-17T07:05:36.724546Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create ner tags for each token in the example transcript and ner tags list\ntags = create_ner_tags(example_1, ner)","metadata":{"_uuid":"7c598b53-6227-4d0c-8908-5a733466d309","_cell_guid":"8c5b7df5-e0ca-4a50-88db-eda378a99aa0","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-17T07:05:38.109095Z","iopub.execute_input":"2023-09-17T07:05:38.109478Z","iopub.status.idle":"2023-09-17T07:05:38.120146Z","shell.execute_reply.started":"2023-09-17T07:05:38.109442Z","shell.execute_reply":"2023-09-17T07:05:38.119183Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loop through each token id and the corresponding ner tag in the input ids and tags lists\nfor ind, tok in enumerate(tokenizer.convert_ids_to_tokens(tokens['input_ids'])):\n    print(tok, tags[ind])","metadata":{"_uuid":"2b60e077-3010-4215-9e66-eecf6e3dd612","_cell_guid":"cc290834-a648-4387-a188-21b71441322c","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-17T07:05:39.409951Z","iopub.execute_input":"2023-09-17T07:05:39.410339Z","iopub.status.idle":"2023-09-17T07:05:39.424293Z","shell.execute_reply.started":"2023-09-17T07:05:39.410308Z","shell.execute_reply":"2023-09-17T07:05:39.423012Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating ner preprocesssed column","metadata":{"_uuid":"9e484e3b-a079-4981-9d9f-df5a903fa138","_cell_guid":"6cb70e4d-c6be-4a60-a8cf-9bb783fe0c54","trusted":true}},{"cell_type":"code","source":"# Measure the execution time of creating ner tags for the train and validation data\n%%time\ntrain['ner_tags'] = train_data.apply(lambda x: create_ner_tags(x['transcript'], x['ner_tags']), axis=1)","metadata":{"_uuid":"ce94e61a-f2ce-4741-bc6c-3089e69b30b8","_cell_guid":"73ef8e70-acb1-4b16-9518-816521facbb5","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-17T07:05:43.375231Z","iopub.execute_input":"2023-09-17T07:05:43.375630Z","iopub.status.idle":"2023-09-17T07:05:46.094512Z","shell.execute_reply.started":"2023-09-17T07:05:43.375600Z","shell.execute_reply":"2023-09-17T07:05:46.093491Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply the create_ner_tags function to the validation data and store the result as a new column\nval['ner_tags'] = val_data.apply(lambda x: create_ner_tags(x['transcript'], x['ner_tags']), axis=1)","metadata":{"_uuid":"36a4ed11-5d57-47eb-bf88-63ad4bb829f3","_cell_guid":"d9b7ba2a-cbda-4c20-910d-97c8a2531aa3","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:26:50.618319Z","iopub.execute_input":"2023-09-17T06:26:50.618873Z","iopub.status.idle":"2023-09-17T06:26:51.389157Z","shell.execute_reply.started":"2023-09-17T06:26:50.618839Z","shell.execute_reply":"2023-09-17T06:26:51.387979Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop the transcript column from the train and validation data\ntrain.drop('transcript', axis=1, inplace=True)\nval.drop('transcript', axis=1, inplace=True)","metadata":{"_uuid":"fbbb7a56-5ccf-4f8b-aac4-72b2f0303fa3","_cell_guid":"ab2a0faa-d3ee-487b-b07c-a4735420c8e2","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-17T06:26:51.390683Z","iopub.execute_input":"2023-09-17T06:26:51.391310Z","iopub.status.idle":"2023-09-17T06:26:51.398995Z","shell.execute_reply.started":"2023-09-17T06:26:51.391277Z","shell.execute_reply":"2023-09-17T06:26:51.397674Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert the train and validation data to Dataset objects from the datasets library\ntrain = Dataset.from_pandas(train)\ntrain = train.rename_column(\"ner_tags\", \"labels\")\n# Rename the ner_tags column to labels in both datasets\nval = Dataset.from_pandas(val)\nval = val.rename_column(\"ner_tags\", \"labels\")","metadata":{"_uuid":"0147c532-a486-4141-b30c-6804c37b695e","_cell_guid":"e2e990c9-a6b4-4064-9781-eddc053eb42b","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:26:51.401000Z","iopub.execute_input":"2023-09-17T06:26:51.401584Z","iopub.status.idle":"2023-09-17T06:26:51.451205Z","shell.execute_reply.started":"2023-09-17T06:26:51.401552Z","shell.execute_reply":"2023-09-17T06:26:51.450352Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the format of both datasets to torch\ntrain.set_format('torch')\nval.set_format('torch')","metadata":{"_uuid":"5b228085-e414-40ae-aa83-788d9830a25c","_cell_guid":"2158bcf8-e267-46bb-89f1-75b6bb6d55cb","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:26:51.452262Z","iopub.execute_input":"2023-09-17T06:26:51.452592Z","iopub.status.idle":"2023-09-17T06:26:51.460445Z","shell.execute_reply.started":"2023-09-17T06:26:51.452560Z","shell.execute_reply":"2023-09-17T06:26:51.459405Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"_uuid":"7429ac0b-b540-46da-8ec3-99566aa56580","_cell_guid":"0e72c788-6c6a-41bc-8c80-c5de1885f408","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:26:51.462053Z","iopub.execute_input":"2023-09-17T06:26:51.462394Z","iopub.status.idle":"2023-09-17T06:26:51.473193Z","shell.execute_reply.started":"2023-09-17T06:26:51.462364Z","shell.execute_reply":"2023-09-17T06:26:51.472088Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the DataCollatorForTokenClassification class from the transformers library\nfrom transformers import DataCollatorForTokenClassification\n# Create a data collator object using the tokenizer\ndata_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)","metadata":{"_uuid":"bd205273-f3fc-4fe9-8a22-4ec11128535f","_cell_guid":"c3eb0793-1b00-48a8-b9f4-fbc32a933fb9","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:26:51.474985Z","iopub.execute_input":"2023-09-17T06:26:51.475349Z","iopub.status.idle":"2023-09-17T06:26:59.543313Z","shell.execute_reply.started":"2023-09-17T06:26:51.475305Z","shell.execute_reply":"2023-09-17T06:26:59.542391Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install evaluate seqeval","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the seqeval evaluation metric from the evaluate module\nimport evaluate\n\nseqeval = evaluate.load(\"seqeval\")","metadata":{"_uuid":"e47d6c32-1de2-4463-b770-aaafd731da20","_cell_guid":"a04b5864-8a18-4de3-8a9f-fe454851118a","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:26:59.544624Z","iopub.execute_input":"2023-09-17T06:26:59.547670Z","iopub.status.idle":"2023-09-17T06:27:02.486382Z","shell.execute_reply.started":"2023-09-17T06:26:59.547631Z","shell.execute_reply":"2023-09-17T06:27:02.485404Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the load_metric function from the datasets library\nfrom datasets import load_metric\nmetric = load_metric(\"seqeval\")","metadata":{"_uuid":"5f866435-eda4-4a6c-8322-8a63ede2ce4e","_cell_guid":"2eb0e882-ab4d-4dc8-a82f-6cd2635a8505","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:27:02.488021Z","iopub.execute_input":"2023-09-17T06:27:02.488450Z","iopub.status.idle":"2023-09-17T06:27:02.948300Z","shell.execute_reply.started":"2023-09-17T06:27:02.488412Z","shell.execute_reply":"2023-09-17T06:27:02.947320Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# labels = [ner_labels[i] for i in train[\"ner_tags\"]]\n# metric.compute(predictions=[labels], references=[labels])","metadata":{"_uuid":"bb120bfa-0c70-4bd6-8e6f-cca825e7aef4","_cell_guid":"85e26d3b-117a-4985-89e9-46f44b0ec8f1","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:27:02.949916Z","iopub.execute_input":"2023-09-17T06:27:02.950296Z","iopub.status.idle":"2023-09-17T06:27:02.956412Z","shell.execute_reply.started":"2023-09-17T06:27:02.950260Z","shell.execute_reply":"2023-09-17T06:27:02.953943Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ner_labels_dict","metadata":{"_uuid":"8e28bc02-9c3d-4e17-bdff-695b8e92ca99","_cell_guid":"dbdb3d4b-2e67-4c12-bce9-a4229a4c8813","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:27:02.957796Z","iopub.execute_input":"2023-09-17T06:27:02.958783Z","iopub.status.idle":"2023-09-17T06:27:02.969978Z","shell.execute_reply.started":"2023-09-17T06:27:02.958750Z","shell.execute_reply":"2023-09-17T06:27:02.968849Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get a list of ner labels from the dictionary keys\nlist(ner_labels.keys())","metadata":{"_uuid":"07be0a84-16ae-4b42-bd94-eb874430bb46","_cell_guid":"37b8443f-a636-4466-ba31-582b380725ec","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:27:02.971501Z","iopub.execute_input":"2023-09-17T06:27:02.972023Z","iopub.status.idle":"2023-09-17T06:27:02.982597Z","shell.execute_reply.started":"2023-09-17T06:27:02.971989Z","shell.execute_reply":"2023-09-17T06:27:02.981409Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a dictionary of id to label mapping for each numeric code\nid2label = {\n    0 : \"OTHER\",\n    1 : \"employerName\",\n    2 : \"employerAddressStreet_name\",\n    3 : \"employerAddressCity\",\n    4 : \"employerAddressState\",\n    5 : \"employerAddressZip\",\n    6 : \"einEmployerIdentificationNumber\",\n    7 : \"employeeName\",\n    8 : \"ssnOfEmployee\",\n    9 : \"box1WagesTipsAndOtherCompensations\",\n    10 : \"box2FederalIncomeTaxWithheld\",\n    11 : \"box3SocialSecurityWages\",\n    12 : \"box4SocialSecurityTaxWithheld\",\n    13 : \"box16StateWagesTips\",\n    14 : \"box17StateIncomeTax\",\n    15 : \"taxYear\"\n}\n# Define a dictionary of label to id mapping for each ner label\nlabel2id = {\n    'OTHER': 0,\n     'employerName': 1,\n     'employerAddressStreet_name': 2,\n     'employerAddressCity': 3,\n     'employerAddressState': 4,\n     'employerAddressZip': 5,\n     'einEmployerIdentificationNumber': 6,\n     'employeeName': 7,\n     'ssnOfEmployee': 8,\n     'box1WagesTipsAndOtherCompensations': 9,\n     'box2FederalIncomeTaxWithheld': 10,\n     'box3SocialSecurityWages': 11,\n     'box4SocialSecurityTaxWithheld': 12,\n     'box16StateWagesTips': 13,\n     'box17StateIncomeTax': 14,\n     'taxYear': 15\n}","metadata":{"_uuid":"8e0e9cbf-3db0-400f-b5a1-45e7e4fbcd1c","_cell_guid":"5996ae48-94cf-4e1b-a9cc-1d6650f2413c","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:27:02.984449Z","iopub.execute_input":"2023-09-17T06:27:02.984822Z","iopub.status.idle":"2023-09-17T06:27:02.994313Z","shell.execute_reply.started":"2023-09-17T06:27:02.984788Z","shell.execute_reply":"2023-09-17T06:27:02.993205Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"font-family:cursive;text-align:center\">⬇️ Training</span>","metadata":{"_uuid":"a7b3b86d-aa27-4f75-986a-ae10558d5cb7","_cell_guid":"0eee4502-d4e8-4131-8ca5-479a9fb52be1","trusted":true}},{"cell_type":"code","source":"# Import the AutoModelForTokenClassification class from the transformers library\nfrom transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n# Load a model for token classification from a pretrained model name, specifying the number of labels and the id2label and label2id dictionaries\nmodel = AutoModelForTokenClassification.from_pretrained(\n    \"distilbert-base-uncased\", num_labels=16, id2label=id2label, label2id=label2id\n)","metadata":{"_uuid":"d5cf4b61-60a4-437c-ac6c-e94ce3c67ca6","_cell_guid":"7024fb52-3855-48d2-a108-46ef5bf9dc7b","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:27:02.996122Z","iopub.execute_input":"2023-09-17T06:27:02.996473Z","iopub.status.idle":"2023-09-17T06:27:07.305052Z","shell.execute_reply.started":"2023-09-17T06:27:02.996442Z","shell.execute_reply":"2023-09-17T06:27:07.304099Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Move the model to the device (cuda or cpu)\nmodel.to(device)","metadata":{"_uuid":"e15ceb0c-0dee-4ee8-8564-cbe89761486e","_cell_guid":"202e84d9-6009-4b50-8273-cde6a30201ef","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-17T06:27:07.306831Z","iopub.execute_input":"2023-09-17T06:27:07.307212Z","iopub.status.idle":"2023-09-17T06:27:13.734402Z","shell.execute_reply.started":"2023-09-17T06:27:07.307175Z","shell.execute_reply":"2023-09-17T06:27:13.733267Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a training arguments object with various hyperparameters and settings for training and evaluation\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/\",\n    learning_rate=2e-5,\n    logging_strategy = 'epoch',\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=20,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    report_to = 'none'\n)","metadata":{"_uuid":"1508aba9-4531-413c-91c4-c3b42ba3195a","_cell_guid":"a507463f-618e-4935-a622-e429e8c4e212","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:27:13.739197Z","iopub.execute_input":"2023-09-17T06:27:13.741590Z","iopub.status.idle":"2023-09-17T06:27:13.753247Z","shell.execute_reply.started":"2023-09-17T06:27:13.741555Z","shell.execute_reply":"2023-09-17T06:27:13.752179Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a trainer object with the model, the training arguments, the train and validation datasets, the tokenizer, the data collator, and the metric\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train,\n    eval_dataset=val,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n#     compute_metrics=metric,\n)","metadata":{"_uuid":"007f6390-a595-4cf3-bc2d-9dfeb6c03423","_cell_guid":"f4cbba1d-2010-48f4-9d6e-bf23614d7242","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:27:13.759142Z","iopub.execute_input":"2023-09-17T06:27:13.762101Z","iopub.status.idle":"2023-09-17T06:27:13.778902Z","shell.execute_reply.started":"2023-09-17T06:27:13.762065Z","shell.execute_reply":"2023-09-17T06:27:13.778026Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model using the trainer object\ntrainer.train()","metadata":{"_uuid":"50abacfd-e8cf-4cfe-a3fa-ee776f292a80","_cell_guid":"ec72e5e9-1596-47ab-a3d7-57e3addfc757","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-17T06:27:13.780636Z","iopub.execute_input":"2023-09-17T06:27:13.780961Z","iopub.status.idle":"2023-09-17T06:33:50.702281Z","shell.execute_reply.started":"2023-09-17T06:27:13.780930Z","shell.execute_reply":"2023-09-17T06:33:50.701146Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"font-family:cursive;text-align:center\">⬇️ Inference</span>","metadata":{"_uuid":"a71e1d42-1914-4a3a-ae15-e04b8ef9c4da","_cell_guid":"d60b0234-86ba-4feb-9756-c5458f39da44","trusted":true}},{"cell_type":"code","source":"from transformers import pipeline\n# Create a classifier object using the ner pipeline, the trained model, the tokenizer, and the device\nclassifier = pipeline(\"ner\", model=model, tokenizer=tokenizer, device=device)\n# Set the tokenizer attribute is_split_into_words to True (this means that the input is already split into words)\nclassifier.tokenizer.is_split_into_words = True","metadata":{"_uuid":"347e043b-bb54-4d36-8c09-05bfbd1f1431","_cell_guid":"e7f27e86-6d77-40a4-bc7f-a9a7c7ead458","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-17T06:33:50.704106Z","iopub.execute_input":"2023-09-17T06:33:50.704533Z","iopub.status.idle":"2023-09-17T06:33:50.713005Z","shell.execute_reply.started":"2023-09-17T06:33:50.704495Z","shell.execute_reply":"2023-09-17T06:33:50.711814Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply the classifier to a list of words\ntokens = classifier([\"77796.34\", \"3759.51\" ,\"withheby\" ,\"2018\", \"W-2\", \"and\" ,\"EARNINGS\", \"SUMMARY\", \"ADP\", \"Employee\"])\n# Create an empty list for storing the labels\nlabels = []\n# Loop through each element in the tokens list\nfor li in tokens:\n    # Loop through each dictionary in the element\n    for dic in li:\n        # Append the entity value from the dictionary to the labels list\n        labels.append(dic['entity'])","metadata":{"_uuid":"de874593-f6a7-486c-9538-e8d0a43ab7f2","_cell_guid":"091416a4-9eee-4827-a25e-7b9db352028e","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-17T06:33:50.714177Z","iopub.execute_input":"2023-09-17T06:33:50.714781Z","iopub.status.idle":"2023-09-17T06:33:50.821605Z","shell.execute_reply.started":"2023-09-17T06:33:50.714744Z","shell.execute_reply":"2023-09-17T06:33:50.820631Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels","metadata":{"_uuid":"18ecb8fd-f261-4a83-ad77-c276585ec003","_cell_guid":"e7a0a11b-223f-4da7-a617-40ea671402dc","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-17T06:33:50.822961Z","iopub.execute_input":"2023-09-17T06:33:50.823276Z","iopub.status.idle":"2023-09-17T06:33:50.831748Z","shell.execute_reply.started":"2023-09-17T06:33:50.823246Z","shell.execute_reply":"2023-09-17T06:33:50.830735Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokens","metadata":{"_uuid":"5d1491f5-f331-4250-80b2-82df006aa336","_cell_guid":"896f1c93-e84e-4eda-a7c9-a8eed4c34bf7","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-17T06:33:50.833854Z","iopub.execute_input":"2023-09-17T06:33:50.834172Z","iopub.status.idle":"2023-09-17T06:33:50.850538Z","shell.execute_reply.started":"2023-09-17T06:33:50.834146Z","shell.execute_reply":"2023-09-17T06:33:50.849673Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a function to extract labels from inference output\ndef extract_labels_from_inference(opt):\n    lab = []\n    for li in opt:\n        lab.append(li[0]['entity'])\n    return lab","metadata":{"_uuid":"17739df1-bfe6-47cb-8f2e-2f3f5eb74d1c","_cell_guid":"8094fa7b-50e9-4956-8798-d2e38553a4ab","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:33:50.852153Z","iopub.execute_input":"2023-09-17T06:33:50.852782Z","iopub.status.idle":"2023-09-17T06:33:50.860845Z","shell.execute_reply.started":"2023-09-17T06:33:50.852750Z","shell.execute_reply":"2023-09-17T06:33:50.859847Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply the function to the tokens list\nextract_labels_from_inference(tokens)","metadata":{"_uuid":"cc55c543-0295-461d-89c7-72da35774b30","_cell_guid":"ebf7d1af-72c7-4cbd-a802-882f491c3a28","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-17T06:33:50.862362Z","iopub.execute_input":"2023-09-17T06:33:50.862719Z","iopub.status.idle":"2023-09-17T06:33:50.874590Z","shell.execute_reply.started":"2023-09-17T06:33:50.862686Z","shell.execute_reply":"2023-09-17T06:33:50.873662Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words = \"77796.34 3759.51 withheby 2018 W-2 and EARNINGS SUMMARY ADP Employee\"\nwords = words.split()","metadata":{"_uuid":"9c4d5fba-5618-4da7-8950-53d511266cf6","_cell_guid":"9630348f-5bb7-4a11-8a3b-cdf558dcd856","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:33:50.877702Z","iopub.execute_input":"2023-09-17T06:33:50.878017Z","iopub.status.idle":"2023-09-17T06:33:50.885934Z","shell.execute_reply.started":"2023-09-17T06:33:50.877980Z","shell.execute_reply":"2023-09-17T06:33:50.884964Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(words)","metadata":{"_uuid":"fb0ca6a1-f04d-4cb5-99b5-49e6016d386c","_cell_guid":"593cbdfa-320d-473d-b3d2-14eacf986698","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:33:50.887304Z","iopub.execute_input":"2023-09-17T06:33:50.887789Z","iopub.status.idle":"2023-09-17T06:33:50.899444Z","shell.execute_reply.started":"2023-09-17T06:33:50.887757Z","shell.execute_reply":"2023-09-17T06:33:50.898510Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(labels)","metadata":{"_uuid":"cdaf2b1a-daef-4d3e-973d-00cade6a0d72","_cell_guid":"6d68eb47-85bb-4510-8faf-b4399418def6","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:33:50.900616Z","iopub.execute_input":"2023-09-17T06:33:50.901572Z","iopub.status.idle":"2023-09-17T06:33:50.911158Z","shell.execute_reply.started":"2023-09-17T06:33:50.901536Z","shell.execute_reply":"2023-09-17T06:33:50.910161Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokens","metadata":{"_uuid":"fb868060-1bb4-4401-8db8-6fe520f38c00","_cell_guid":"08bdb59d-bb25-4189-880d-85911e0d9cc7","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-17T06:33:50.912647Z","iopub.execute_input":"2023-09-17T06:33:50.913104Z","iopub.status.idle":"2023-09-17T06:33:50.928479Z","shell.execute_reply.started":"2023-09-17T06:33:50.913072Z","shell.execute_reply":"2023-09-17T06:33:50.927556Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preprocess the words using the tokenizer (without adding special tokens)\npreprocessed_tokens = tokenizer(words, is_split_into_words=True, truncation=True, add_special_tokens = False)","metadata":{"_uuid":"22a7419c-2900-45c9-9a1c-3c933c60ae8b","_cell_guid":"500d2429-5fea-4631-aea2-bd1ded7ac32f","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:33:50.929524Z","iopub.execute_input":"2023-09-17T06:33:50.930446Z","iopub.status.idle":"2023-09-17T06:33:50.939809Z","shell.execute_reply.started":"2023-09-17T06:33:50.930409Z","shell.execute_reply":"2023-09-17T06:33:50.938899Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessed_tokens","metadata":{"_uuid":"b5acb6d9-b0eb-4f0d-a516-d4d5458319e6","_cell_guid":"bab01689-bbd8-4a9f-b28e-7a4bd78594ba","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:33:50.942252Z","iopub.execute_input":"2023-09-17T06:33:50.943141Z","iopub.status.idle":"2023-09-17T06:33:50.952391Z","shell.execute_reply.started":"2023-09-17T06:33:50.943111Z","shell.execute_reply":"2023-09-17T06:33:50.951414Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference on val data","metadata":{"_uuid":"6ac8f1ca-1366-4831-b249-5f3193085a85","_cell_guid":"64fac273-e6f9-4b8d-acbe-b25e60e3b3b8","trusted":true}},{"cell_type":"code","source":"# Define a function to load validation data from a given path\ndef load_val_data(path):\n    directory = path\n\n    tsv_file = glob.glob(directory + '/*.tsv')\n\n    data = pd.DataFrame(columns = ['transcript'])\n\n    for filename in tsv_file:\n        data_i = pd.read_csv(filename, header=None)\n        data_i.columns = ['start_index', 'end_index', 'x_top_left', 'y_top_left', 'x_bottom_right', 'y_bottom_right', 'transcript']\n        data_i.dropna(subset=['transcript'], inplace=True)\n        \n        transcript = data_i['transcript'].to_list()\n        \n        data.loc[len(data)] = [transcript]\n        \n    return data","metadata":{"_uuid":"fc75d4ae-b86b-4872-9492-d34e5f1c8b33","_cell_guid":"f818ca3e-af5d-420e-b50f-d32d6a57f054","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:33:50.953645Z","iopub.execute_input":"2023-09-17T06:33:50.954385Z","iopub.status.idle":"2023-09-17T06:33:50.963932Z","shell.execute_reply.started":"2023-09-17T06:33:50.954332Z","shell.execute_reply":"2023-09-17T06:33:50.962937Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the validation data without labels from a given path\nval_data_without_labels = load_val_data('/kaggle/input/demo-data/dataset/val/boxes_transcripts')","metadata":{"_uuid":"4c630509-8025-489c-947b-2ea03c8b7d40","_cell_guid":"30149c36-d4f6-4fbd-812d-7d36358d744d","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:33:50.965394Z","iopub.execute_input":"2023-09-17T06:33:50.966350Z","iopub.status.idle":"2023-09-17T06:33:52.727362Z","shell.execute_reply.started":"2023-09-17T06:33:50.966316Z","shell.execute_reply":"2023-09-17T06:33:52.726348Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the third transcript from the validation data without labels\ntok = val_data_without_labels['transcript'][2]","metadata":{"_uuid":"bf28cf69-02ca-4a9e-aead-7645956040be","_cell_guid":"54b036af-e00c-4f67-bd77-12d910c30dcc","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:33:52.728953Z","iopub.execute_input":"2023-09-17T06:33:52.729831Z","iopub.status.idle":"2023-09-17T06:33:52.734608Z","shell.execute_reply.started":"2023-09-17T06:33:52.729797Z","shell.execute_reply":"2023-09-17T06:33:52.733583Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tok, len(tok)","metadata":{"_uuid":"fa6ded18-ee7c-432d-af73-236cfa325dd5","_cell_guid":"81901365-c1a4-44e1-8b71-0aab5cb1e147","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-17T06:33:52.738472Z","iopub.execute_input":"2023-09-17T06:33:52.739070Z","iopub.status.idle":"2023-09-17T06:33:52.759702Z","shell.execute_reply.started":"2023-09-17T06:33:52.739011Z","shell.execute_reply":"2023-09-17T06:33:52.758510Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a function to predict the ner tags for a given transcript\ndef predict_val(example):\n    ner_tags = []\n    len_example = len(example)\n    if len_example > 300:\n        \n        example_1 = example[:(len_example//2)]\n        example_2 = example[(len_example//2):]\n        \n        lab_1 = classifier(example_1)\n        lab_2 = classifier(example_2)\n        \n        lab_1 = extract_labels_from_inference(lab_1)\n        lab_2 = extract_labels_from_inference(lab_2)\n        \n        ner_tags += lab_1\n        ner_tags += lab_2\n    \n    else:\n        \n        lab = classifier(example)\n        lab = extract_labels_from_inference(lab)\n        ner_tags += lab\n    \n    return ner_tags","metadata":{"_uuid":"9366e2aa-0228-402a-b8c1-13cdb9286c5b","_cell_guid":"a1bfb22d-b305-4aae-a7af-063cd80f72b2","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:33:52.761097Z","iopub.execute_input":"2023-09-17T06:33:52.761667Z","iopub.status.idle":"2023-09-17T06:33:52.768614Z","shell.execute_reply.started":"2023-09-17T06:33:52.761619Z","shell.execute_reply":"2023-09-17T06:33:52.767725Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get all the tsv files in a given directory\n\ntsv_file = glob.glob('/kaggle/working/val/boxes_transcripts' + '/*.tsv')","metadata":{"_uuid":"bf5aeee3-ed58-4fe2-899f-5f4dcc98bceb","_cell_guid":"5ba71a77-e468-449d-920e-91e6ceb20f25","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:33:52.769895Z","iopub.execute_input":"2023-09-17T06:33:52.770222Z","iopub.status.idle":"2023-09-17T06:33:52.798105Z","shell.execute_reply.started":"2023-09-17T06:33:52.770191Z","shell.execute_reply":"2023-09-17T06:33:52.797152Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(tsv_file)","metadata":{"_uuid":"289586b8-8d02-45d6-a701-aa551eabd399","_cell_guid":"612f8f91-c3cc-44c3-bd4c-ed54b4df6af2","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:33:52.799523Z","iopub.execute_input":"2023-09-17T06:33:52.799909Z","iopub.status.idle":"2023-09-17T06:33:52.813253Z","shell.execute_reply.started":"2023-09-17T06:33:52.799877Z","shell.execute_reply":"2023-09-17T06:33:52.812248Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n# Define a function to generate validation tsv files with predicted labels\ndef generate_val_tsvs(path):\n    \n    if not os.path.exists('val'):\n        os.mkdir('val')\n        os.mkdir('val/boxes_transcripts')\n    \n    directory = path\n\n    tsv_file = glob.glob(directory + '/*.tsv')\n\n    for filename in tsv_file:\n        data_i = pd.read_csv(filename, header=None)\n        data_i.columns = ['start_index', 'end_index', 'x_top_left', 'y_top_left', 'x_bottom_right', 'y_bottom_right', 'transcript']\n        data_i.dropna(subset=['transcript'], inplace=True)\n        \n        transcript = data_i['transcript'].to_list()\n        \n        pred = predict_val(transcript)\n        \n        data_i['field'] = pred\n        \n        data_i.to_csv(f\"val/boxes_transcripts/{filename.split('/')[-1]}\", index=False, header=None)","metadata":{"_uuid":"0cc5806a-c93f-459d-adbf-c88b41491d6c","_cell_guid":"bb0c6cea-3349-427a-ba09-15faeeafffc6","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:34:18.047227Z","iopub.execute_input":"2023-09-17T06:34:18.047908Z","iopub.status.idle":"2023-09-17T06:34:18.055396Z","shell.execute_reply.started":"2023-09-17T06:34:18.047875Z","shell.execute_reply":"2023-09-17T06:34:18.054421Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Measure the execution time of generating the validation tsv files with labels\n%%time\ngenerate_val_tsvs('/kaggle/input/demo-data/dataset/val/boxes_transcripts')","metadata":{"_uuid":"c3c7eba4-f227-4593-9a42-9dff40f6c43e","_cell_guid":"f2fa0750-7f7e-4903-be02-c70d06607b44","collapsed":false,"scrolled":true,"execution":{"iopub.status.busy":"2023-09-17T06:34:19.030236Z","iopub.execute_input":"2023-09-17T06:34:19.030947Z","iopub.status.idle":"2023-09-17T06:43:39.496391Z","shell.execute_reply.started":"2023-09-17T06:34:19.030912Z","shell.execute_reply":"2023-09-17T06:43:39.495272Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <span style=\"font-family:cursive;text-align:center\">⬇️ Generating metrics.tsv</span>","metadata":{"_uuid":"2bf3f4f0-ee7e-4aea-a1b8-c65f87df0f8d","_cell_guid":"ad689d6f-6c60-41ae-9c56-da9631f06b8c","trusted":true}},{"cell_type":"code","source":"import os\nimport csv\nimport pandas as pd\n\n'''\nEntities:\n1. employerName\n2. employerAddressStreet_name\n3. employerAddressCity\n4. employerAddressState\n5. employerAddressZip\n6. einEmployerIdentificationNumber\n7. employeeName\n8. ssnOfEmployee\n9. box1WagesTipsAndOtherCompensations\n10. box2FederalIncomeTaxWithheld\n11. box3SocialSecurityWages\n12. box4SocialSecurityTaxWithheld\n13. box16StateWagesTips\n14. box17StateIncomeTax\n15. taxYear\n'''\n\n\n\n'''\nDescription: The fuction yields the standard precision, recall and f1 score metrics\n\narguments:\n    TP -> int\n    FP -> int\n    FN -> int\n\nreturns: float, float, float\n'''\ndef performance(TP, FP, FN):\n    \n    if (TP+FP) == 0:\n        precision = 0\n    else:\n        precision = TP/float((TP+FP))\n        \n    if (TP+FN) == 0:\n        recall = 0\n    else:\n        recall = TP/float((TP+FN))\n    \n    if (recall!= 0) and (precision!= 0):\n        f1_score = (2.0*precision*recall)/(precision+recall)\n    else:\n        f1_score = 0\n    \n    return precision, recall, f1_score\n    \n    \n    \n    \n'''\nDescription: The fuction yields a dataframe containing entity-wise performance metrics\n\narguments:\n    true_labels -> list\n    pred_labels -> lisyt\n    \nreturns: pandas dataframe\n'''\ndef get_dataset_metrics(true_labels, pred_labels):\n    \n    metrics_dict = dict()\n    \n    for true_label, pred_label in zip(true_labels, pred_labels):\n        if true_label not in metrics_dict:\n            metrics_dict[true_label] = {\"TP\":0, \"FP\":0, \"FN\":0, \"Support\":0}\n        \n        if true_label != \"OTHER\":\n            metrics_dict[true_label][\"Support\"] += 1\n            \n            if true_label == pred_label:\n                metrics_dict[true_label][\"TP\"] += 1\n            \n            elif pred_label == \"OTHER\":\n                metrics_dict[true_label][\"FN\"] += 1\n            \n        else:\n            if pred_label != \"OTHER\":\n                metrics_dict[pred_label][\"FP\"] += 1\n           \n    df = pd.DataFrame()\n    \n    for field in metrics_dict:\n        precision, recall, f1_score = performance(metrics_dict[field][\"TP\"], metrics_dict[field][\"FP\"], metrics_dict[field][\"FN\"])\n        support = metrics_dict[field][\"Support\"]\n        \n        if field != \"OTHER\":\n            temp_df = pd.DataFrame([[precision, recall, f1_score, support]], columns=[\"Precision\", \"Recall\", \"F1-Score\", \"Support\"], index=[field])\n#             df = df.append(temp_df)\n            df = pd.concat([df, temp_df])\n    \n    return df\n\n\n\n\n'''\nDescription: The fuction yields a dataframe containing entity-wise performance metrics for a single document\n(make sure the doc id is the same)\n\narguments:\n    doc_true -> tsv file with with labels in the last column (8 th column (1-indexed))\n    doc_pred -> tsv file with labels in the last column (8 th column (1-indexed)), as predicted by the model\n    \nreturns: list, list\n'''\ndef get_doc_labels(doc_true, doc_pred):\n\n    true_labels = [row[-1] for row in csv.reader(open(doc_true, \"r\"))]\n    pred_labels = [row[-1] for row in csv.reader(open(doc_pred, \"r\"))]\n\n    return true_labels, pred_labels\n\n'''\nDescription: The fuction yields a dataframe containing entity-wise performance metrics for all documents\n(make sure the doc ids are the same in both the paths)\n\narguments:\n    doc_true -> string (directory containing the ground truth tsv files)\n    doc_pred -> string (directory containing the predicted tsv files)\n    save -> bool (saves the metrics file in your working directory)\nreturns: pandas dataframe\n'''\ndef get_dataset_labels(true_path, pred_path, save=False):\n    \n    y_true, y_pred = [], []\n    \n    for true_file in os.listdir(true_path):\n        for pred_file in os.listdir(pred_path):\n            if (\".tsv\" in true_file) and (\".tsv\" in pred_file):\n                if true_file == pred_file:\n                    \n                    true_file, pred_file = f\"{true_path}/{true_file}\", f\"{pred_path}/{pred_file}\"\n                    true_labels, pred_labels = get_doc_labels(true_file, pred_file)\n                    \n                    y_true.extend(true_labels)\n                    y_pred.extend(pred_labels)\n            \n    df = get_dataset_metrics(y_true, y_pred)\n    print(df)\n    if save == True:\n        df.to_csv(\"eval_metrics.tsv\")\n\n\n\nif __name__ == \"__main__\":\n    \n    # template to run your own evaluation\n\n    doc_true = f\"/kaggle/input/demo-data/dataset/val_w_ann/boxes_transcripts_labels\"\n    doc_pred = f\"/kaggle/working/val/boxes_transcripts\"\n\n    get_dataset_labels(doc_true, doc_pred, save=True)","metadata":{"_uuid":"89545ef8-9cd7-4350-9c50-b0002b16c1b7","_cell_guid":"6f1b0c95-cfe1-4476-9ff7-b548ed1c0e52","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:54:34.390647Z","iopub.execute_input":"2023-09-17T06:54:34.391017Z","iopub.status.idle":"2023-09-17T06:54:34.871636Z","shell.execute_reply.started":"2023-09-17T06:54:34.390986Z","shell.execute_reply":"2023-09-17T06:54:34.870655Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_df = pd.read_csv(\"/kaggle/working/eval_metrics.tsv\")\neval_df","metadata":{"_uuid":"0b8d9226-1a8b-4013-991b-5a6cac1347b7","_cell_guid":"29d2eb89-6028-4176-9a6b-ecaf287dfff4","collapsed":false,"execution":{"iopub.status.busy":"2023-09-17T06:54:56.123287Z","iopub.execute_input":"2023-09-17T06:54:56.123963Z","iopub.status.idle":"2023-09-17T06:54:56.141500Z","shell.execute_reply.started":"2023-09-17T06:54:56.123931Z","shell.execute_reply":"2023-09-17T06:54:56.140401Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}